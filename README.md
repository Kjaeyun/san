# Sign Language Recognition and Translation 

This repository provides a pytorch-based implementation of Context Matters: Self-Attention for Sign Language Recognition.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. 

## Updates

* Paper submitted into ICPR 2020.
  

### Prerequisites

Ofcourse, you need to have python, here we are using python 3.6. So you need to install python3.

```
sudo apt-get update
sudo apt-get install python3.6
```

Install Pytorch a very cool machine learning library and the CUDA environment. 

```
https://pytorch.org/
```

Install opencv2.
```
sudo apt-get install python-opencv
```

Other dependencies (numpy, etc..).
```
pip install numpy
```


## Architecture

<img src="https://github.com/faresbs/slrt/blob/master/images/arch.png" width="800" height="600" />

## Evaluation 


## Training

## Built With

* [Pytorch](https://pytorch.org/) - ML library
* [Opencv](https://opencv.org/) - Open Source Computer Vision Library

## TO DO:

## Results

### Quantitative Analysis

<img src="https://github.com/faresbs/slrt/blob/master/images/table.png" width="300" height="400" />

### Qualitative Analysis

<img src="https://github.com/faresbs/slrt/blob/master/images/heatmap.png width="800" height="600" />

## Datasets

### Sign language recognition

### Sign language translation


## Contributing

You are free to use this project or contribute that would be cool. Please contact me if you face any problems running the code or if you require any clarification.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Authors


## Acknowledgments




